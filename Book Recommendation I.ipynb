{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Recommendation Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "Many online businesses rely on customer reviews and ratings.Explicit feedback is especially important in major B2B sectors .Consumer product sectors like CPG, Telecom, entertainment depends on consumer ratings and use their feedback and historical transactions to build recommendations that are personalized and most relevant to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "Book ratings from individual Goodreads users.\n",
    "\n",
    "The data is collected from goodreads .Data is at user-book level .Data has 50k+ user ratings for 10k+ books.\n",
    "\n",
    "The data is explicit in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow of problem solving\n",
    "\n",
    "    1) EDA and getting understanding of data \n",
    "    2) Traditional method and its shortcomings\n",
    "    3) Trying to use it on scale using pyspark\n",
    "    4) Trying to improve the model using deep learning \n",
    "    5) Further improvements and underlying biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "r = pd.read_csv( 'data/ratings.csv' )\n",
    "b = pd.read_csv( 'data/books.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.rating.hist( bins = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_book = r.groupby( 'book_id' ).book_id.apply( lambda x: len( x ))\n",
    "reviews_per_book.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_book.sort_values().head( 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_book = r.groupby( 'book_id' ).book_id.apply( lambda x: len( x ))\n",
    "reviews_per_book.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_book.sort_values().head( 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional method\n",
    "\n",
    " We are not opting for user based similarity method as it will take too much time when there are lots of users.\n",
    " \n",
    " We will try item based similarity method.\n",
    " \n",
    "Here we are building the item-item similarity matrix .We first convert build a list of dictionary. Each dictionary corresponds to a single book. The user_id is the key, while rating given by the user for the book is its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDictonaries=[]\n",
    "indexMap = {}\n",
    "reverseIndexMap = {}\n",
    "ptr=0;\n",
    "testdf = r\n",
    "testdf=testdf[['user_id','rating']].groupby(testdf['book_id'])\n",
    "for groupKey in testdf.groups.keys():\n",
    "    tempDict={}\n",
    "\n",
    "    groupDF = testdf.get_group(groupKey)\n",
    "    for i in range(0,len(groupDF)):\n",
    "        tempDict[groupDF.iloc[i,0]]=groupDF.iloc[i,1]\n",
    "    indexMap[ptr]=groupKey\n",
    "    reverseIndexMap[groupKey] = ptr\n",
    "    ptr=ptr+1\n",
    "    listOfDictonaries.append(tempDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use sklearn's DictVectorizer() function to create vectors corresponding to each book. We are trying to create a vector space with users as column vectors. Each point in the vector space represents a book. Rating of the book given an user is its magnitude. We then calculate similarity/distance between books in this vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dictVectorizer = DictVectorizer(sparse=True)\n",
    "vector = dictVectorizer.fit_transform(listOfDictonaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally use sklearn's consine_similarity function to calculate pairwise similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "pairwiseSimilarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def printBookDetails(bookID):\n",
    "    print(\"Title:\", b[b['id']==bookID]['original_title'].values[0])\n",
    "    print(\"Author:\",b[b['id']==bookID]['authors'].values[0])\n",
    "    print(\"Printing Book-ID:\",bookID)\n",
    "    print(\"=================++++++++++++++=========================\")\n",
    "\n",
    "\n",
    "def getTopRecommandations(bookID):\n",
    "    row = reverseIndexMap[bookID]\n",
    "    print(\"------INPUT BOOK--------\")\n",
    "    printBookDetails(bookID)\n",
    "    print(\"-------RECOMMENDATIONS----------\")\n",
    "    similarBookIDs = [printBookDetails(indexMap[i]) for i in np.argsort(pairwiseSimilarity[row])[-7:-2][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTopRecommandations(1245)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "There are better distance/similarity measures for these kind of problems.We can also try KNN too.\n",
    "\n",
    "Traditional recommender are yet used and give descent results .May be we can include content (e.g. description of book ) or some other information too to build hybrid model.\n",
    "\n",
    "This also suffers from cold start problem , where we can use the most popular item to recommend if we don't have a history .\n",
    "\n",
    "We can also build a hybrid recommender which combines both collaborative and content based recommender ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark to see how can we scale it on big data\n",
    "\n",
    "The recommendation system can work on PySpark, which is a popular framework for Big Data analysis.\n",
    "\n",
    "We are using Alternating Least Squares model (ALS) with a non-negative matrix factorization algorithm to factorize the user-book matrix. \n",
    "\n",
    "Then I can approximate the original matrix and predict the blank cells (user haven't read this book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "from pyspark.sql.functions import col, min, max, avg, lit\n",
    "\n",
    "# Machine Learning (ML)\n",
    "from pyspark.ml.recommendation import ALS # Alternating Least Squares model\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator # Cross-Validation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # Performance metric\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "from matplotlib import rcParams\n",
    "sns.set(context='notebook', style='whitegrid', rc={'figure.figsize': (18,4)})\n",
    "rcParams['figure.figsize'] = 18,4\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Setting random seed for reproducability\n",
    "SEED = 42\n",
    "np.random.seed = SEED\n",
    "np.random.set_state = SEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName = \"Book-Recommendation\")\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into Spark DataFrame\n",
    "ratings = spark.read.csv('data/ratings.csv',\n",
    "                         header = True,\n",
    "                         inferSchema=True)\n",
    "print(type(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_read = spark.read.csv('data/to_read.csv',\n",
    "                         header = True,\n",
    "                         inferSchema=True)\n",
    "print(type(to_read))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will do it on small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.sample(withReplacement = False, \n",
    "                         fraction = 0.01, # 1% of observation\n",
    "                         seed = 2019)\n",
    "print(ratings.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.user_id,\n",
    "                         ratings.book_id,\n",
    "                         ratings.rating.cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Generic ALS model - without hyperparameters\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"book_id\", ratingCol=\"rating\", \n",
    "          nonnegative = True, # Non negative matrix factorization\n",
    "          coldStartStrategy = \"drop\", # What to do if user do not appear in train and test set\n",
    "          implicitPrefs = False) # Explicit preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], \n",
    "                                    seed = 1234)\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100]) \\\n",
    "            .addGrid(als.maxIter, [5, 50, 100]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator as RMSE\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\", \n",
    "                                labelCol = \"rating\", \n",
    "                                predictionCol = \"prediction\")\n",
    "# Print length of evaluator\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator = als, \n",
    "                    estimatorParamMaps = param_grid, \n",
    "                    evaluator = evaluator, \n",
    "                    numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generic model to the 'train' dataset\n",
    "als_mod = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = als_mod.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the RMSE of test_predictions\n",
    "print(evaluator.evaluate(test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible improvements:\n",
    "\n",
    "Use the latent features to extract unobservable features that imply some kind of user preferences.\n",
    "\n",
    "Add more information about the products.\n",
    "\n",
    "Will try deep learning to improve the RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
